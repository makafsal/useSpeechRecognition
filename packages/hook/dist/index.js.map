{"version":3,"file":"index.js","sources":["../src/useSpeechRecognition.ts"],"sourcesContent":["import { useCallback, useEffect, useRef, useState } from \"react\";\n\nexport const useSpeechRecognition = (commands = []) => {\n  const recognition = useRef<any>(null);\n  // State\n  const [isListening, setIsListening] = useState(false);\n  const [errorMessage, setErrorMessage] = useState(\"\");\n  const [result, setResult] = useState(\"\");\n\n  const grammar = `#JSGF V1.0; grammar commands; public <command> = ${commands.join(\n    \" | \"\n  )};`;\n\n  useEffect(() => {\n    const _window = window as any;\n    const SpeechRecognition =\n      _window?.SpeechRecognition || _window?.webkitSpeechRecognition;\n\n    if (!SpeechRecognition) {\n      console.error(\"SpeechRecognition API is not supported in this browser.\");\n      return;\n    }\n    const SpeechGrammarList =\n      _window?.SpeechGrammarList || _window?.webkitSpeechGrammarList;\n\n    recognition.current = new SpeechRecognition();\n\n    const speechRecognitionList = new SpeechGrammarList();\n\n    speechRecognitionList.addFromString(grammar, 1);\n\n    recognition.current.grammars = speechRecognitionList;\n    recognition.current.continuous = false;\n    recognition.current.lang = \"en-US\";\n    recognition.current.interimResults = false;\n    recognition.current.maxAlternatives = 1;\n    recognition.current.onerror = (event: any) => onError(event);\n    recognition.current.onresult = (event: any) => onResult(event);\n\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, []);\n\n  const onStop = useCallback(() => {\n    recognition?.current.stop();\n    setIsListening(false);\n  }, []);\n\n  const onStart = useCallback(() => {\n    if (isListening) {\n      onStop();\n      return;\n    }\n\n    setErrorMessage(\"\");\n    setResult(\"\");\n\n    recognition?.current.start();\n    setIsListening(true);\n\n    setTimeout(() => onStop(), 8000);\n  }, [isListening, onStop]);\n\n  const onResult = (event: any) => {\n    const command = event.results[0][0].transcript;\n    setResult(command);\n    onStop();\n  };\n\n  const onError = (event: any) => {\n    setErrorMessage(\"No voice detected.\");\n    onStop();\n  };\n\n  return {\n    onStart,\n    onStop,\n    isListening,\n    errorMessage,\n    result\n  };\n};"],"names":["commands","recognition","useRef","isListening","setIsListening","useState","errorMessage","setErrorMessage","result","setResult","grammar","join","useEffect","_window","window","SpeechRecognition","webkitSpeechRecognition","console","error","SpeechGrammarList","webkitSpeechGrammarList","current","speechRecognitionList","addFromString","grammars","continuous","lang","interimResults","maxAlternatives","onerror","event","onError","onresult","onResult","onStop","useCallback","stop","onStart","start","setTimeout","command","results","transcript"],"mappings":"wHAEoC,CAACA,EAAW,MAC9C,MAAMC,EAAcC,SAAY,OAEzBC,EAAaC,GAAkBC,EAAQA,UAAC,IACxCC,EAAcC,GAAmBF,EAAQA,SAAC,KAC1CG,EAAQC,GAAaJ,EAAQA,SAAC,IAE/BK,EAAU,oDAAoDV,EAASW,KAC3E,UAGFC,EAAAA,WAAU,KACR,MAAMC,EAAUC,OACVC,EACJF,GAASE,mBAAqBF,GAASG,wBAEzC,IAAKD,EAEH,YADAE,QAAQC,MAAM,2DAGhB,MAAMC,EACJN,GAASM,mBAAqBN,GAASO,wBAEzCnB,EAAYoB,QAAU,IAAIN,EAE1B,MAAMO,EAAwB,IAAIH,EAElCG,EAAsBC,cAAcb,EAAS,GAE7CT,EAAYoB,QAAQG,SAAWF,EAC/BrB,EAAYoB,QAAQI,YAAa,EACjCxB,EAAYoB,QAAQK,KAAO,QAC3BzB,EAAYoB,QAAQM,gBAAiB,EACrC1B,EAAYoB,QAAQO,gBAAkB,EACtC3B,EAAYoB,QAAQQ,QAAWC,GAAeC,IAC9C9B,EAAYoB,QAAQW,SAAYF,GAAeG,EAASH,EAAM,GAG7D,IAEH,MAAMI,EAASC,EAAAA,aAAY,KACzBlC,GAAaoB,QAAQe,OACrBhC,GAAe,EAAM,GACpB,IAEGiC,EAAUF,EAAAA,aAAY,KACtBhC,EACF+B,KAIF3B,EAAgB,IAChBE,EAAU,IAEVR,GAAaoB,QAAQiB,QACrBlC,GAAe,GAEfmC,YAAW,IAAML,KAAU,KAAK,GAC/B,CAAC/B,EAAa+B,IAEXD,EAAYH,IAChB,MAAMU,EAAUV,EAAMW,QAAQ,GAAG,GAAGC,WACpCjC,EAAU+B,GACVN,GAAQ,EAGJH,EAAWD,IACfvB,EAAgB,sBAChB2B,GAAQ,EAGV,MAAO,CACLG,UACAH,SACA/B,cACAG,eACAE,SACD"}